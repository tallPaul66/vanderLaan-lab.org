---
date: 2016-03-09T00:11:02+01:00
title: Mark van der Laan, Jiann-Ping Hsu/Karl E. Peace Professor in Biostatistics
<!-- type: index -->
<!-- weight: 10 -->
---

<!-- <img style="float: left;margin:0 5rem 0 0" src="IMG_7950-2.jpg" width="35%" height="35%">
<br>
 -->

Mark van der Laan, Ph.D. is a Professor of Biostatistics and Statistics at UC Berkeley. His research interests include statistical methods in genomics (i.e., computational biology), survival analysis, censored data, targeted maximum likelihood estimation in semiparametric models, causal inference, data adaptive loss-based super learning, and multiple testing.

His research group developed loss-based super learning in semiparametric models, based on cross-validation, as a generic optimal tool for estimation of infinite dimensional parameters, such as nonparametric density estimation and prediction based on censored and uncensored data. Building on this super learning methodology, his research group developed targeted maximum likelihood estimation of a target parameter of the data generating distribution in semiparametric models, as a new generic optimal methodology for statistical inference. These general statistical approaches are applied across a large variety of applications such as in the analysis of clinical trials, assessment of (causal) effects in observational studies and the analysis of large genomic data sets.

Details about Mark's education, experience, and publications can be found in his CV.

Mark is also the founder of Target Analytics, a company that offers statistical consulting services and translates state-of-the-art causal inference methodology into user-friendly software products.

Mark came to UC Berkeley from the Netherlands' University of Utrecht, where he studied mathematics (1985-1990) and obtained his Ph.D. (1993). He completed his thesis, "Efficient and inefficient estimation in semiparametric models," under the guidance of Prof. Richard D. Gill.

In 1994, Mark was a Neyman Visiting Professor in the Statistics Department at UC Berkeley. Subsequently, he accepted a tenure track position in the Division of Biostatistics, School of Public Health at Berkeley, and became an Associate Professor in Biostatistics in July 1997. By July 2000, Mark was a Professor in Biostatistics and Statistics.

Having taught introductory courses in Biostatistics for Public Health students, he currently teaches classes on censored data, survival analysis, causal inference, data adaptive loss-based estimation, adaptive designs, targeted maximum likelihood estimation, and multiple testing. He has been or is Associate Editor for Biometrics (1997-2003), Associate Editor Lifetime Data Models (1996-2000), Associate Editor for Journal of Statistical Planning and Inference, Statistical Applications in Genetics and Molecular Biology, Annals of Statistics, Journal of the American Statistical Association, founding editor of the International Journal of Biostatistics, Electronic Journal of Statistics, Journal of Statistical Medical Research. He is also Director of the Biostatistics and Computing core of the Superfund Research Program of a Center on Genomics in Environmental Science in the School of Public Health, headed by Professor Martyn Smith.

Several grants have been awarded to Mark, including an NIH FIRST Award research grant for the period 1996-2001 to work on "Locally Efficient Estimation in Censored Data Models "; an NIAID grant for 1999-2002 to develop a unified methodology for censored data and causal inference; a 3 year grant he received in March 2001 from the Life Science Informatics Institute and its industrial partner, biotech company Chiron, to create statistical methods for data structures involving microarray data on 
complete (human) genomes; an NIH grant "Statistical Analysis of Longitudinal Studies with Gene Expression Data " (2002-2006); an NIH grant "Data Adaptive Estimation in Epidemiology and Genomics " (2004-2007), and an NIH grant ‘’Targeted Maximum Likelihood Estimation’’ (2008-2011).

Mark received the 2004 Mortimer Spiegelman Award. The Mortimer Spiegelman Award was established in 1969 by his family and is awarded annually to a young statistician for outstanding contributions in health statistics. It is presented by the Statistics Section of the American Public Health Association (APHA).

Mark received the van Dantzig Award on April 11, 2005. Once in every 5 years the Dutch Statistical Assocation presents the van Dantzig Award, which is the most prestigious award in operation research and Statistics in the Netherlands. The award is in memory of Prof. Dr. D. van Dantzig, the founder of Dutch mathematical statistics. The van Dantzig Award is presented to a Dutch statistician or operation researcher who is not older than 40 years and who during the past 5 years has made an exceptional contribution --- either theoretical, or practical--- to the field. Previous recipients of the van Dantzig Award are Van Zwet (1970), Van Meurs (1975), Hordijk (1980), Rinnooy Kan (1985), Gill (1990), Ridder (1995), and van der Vaart (2000).

Mark was selected to present the 2005 Lefkopoulou distinguished lectureship, Harvard University, Boston, September 15, 2005. This lectureship is an award from theDepartment of Biostatistics, Harvard University, Boston. The program was established in honor of the late Myrto Lefkopoulou, a faculty member and student in the Department of Biostatistics. The lectureship is awarded to a promising biostatistical scientist who has made contributions to collaborative or methodological 
research in the application of statistical methods to biology or medicine or to excellence in the teaching of biostatistics.

Mark has been awarded the UC Berkeley Chancellor Endowed Chair 2005-2008, and the long-term Jiann-Ping Hsu/Karl E. Peace Endowed Chair in Biostatistics starting 2005.

Mark has also been selected to be featured on the cover of one of the five well-respected Tan Applied Mathematics series textbooks, edited by Applied Mathematics for Brooks/Cole, a division of Thomson Higher Education. Five applied mathematicians have been featured on the cover of each of the five texts in the hope that seeing a successful applied mathematician will motivate readers (students) of these texts to learn and to use the applied mathematical skills they acquire in their future careers. [Applied Mathematics Book Cover](./AppliedMathSEcover.jpg)

Nick Jewell and Mark van der Laan received the 2005 COPPS Snedecor Award for the paper 'Case-control current status data' in Biometrika, 2004, v91, pp. 529-541. The Snedecor award is presented every two years. The criteria for the award are to an individual(s) who has been (1) instrumental in the development of statistical theory in biometry, and (2) who has a noteworthy publication in biometry within three years of the date of the award. The award is also a tribute to the overall contribution to biometry.

Mark received the 2005 (COPSS) Presidential Award. The Committee of Presidents of Statistical Societies (COPSS) Awards are jointly sponsored by the American Statistical Association, the Institute of Mathematical Statistics, the Biometric Society ENAR, the Biometric Society WNAR, and the Statistics Society of Canada. The Presidential Award is presented annually to a young member of one of the participating societies of COPSS. The award is presented in recognition of outstanding contributions to the statistics profession. The President's Award is granted to an individual who has not yet reached his or her 41st birthday during the calendar year of the award.

<br>
<br>

## [Curriculum Vitae](./vanderlaan-cv-20161112.pdf)


## Research interests

Mark van der Laan’s main research interests are:

1) Developing optimal statistical methodology and theory for analyzing high dimensional and complex data sets, involving censoring, missingness, and biased sampling, under realistic assumptions resulting in semiparametric models,

2) Causal Inference in longitudinal observational studies and randomized controlled trials with possible informative treatment assignment and informative censoring, and

3) Statistical Methods in Genomics (i.e., Computational Biology, Machine Learning), a field made possible by advances in technology that have enabled accurate, low-cost, genome-wide monitoring of mRNAs, DNA's, proteins and other important biomolecules in cells throughout an organism, over time and space.

These three research areas overlap extensively, since statisticians will encounter typical data sets that involve longitudinal data, where gene-expression profiles, SNP-profiles, DNA-profiles, and biomarker data are measured at various points in time, in addition to the usual covariates and time till event outcomes.

In response to the challenges dealing with the curse of dimensionality and the complexity of the data-generating mechanism, Mark’s research has converged to a new approach to statistical learning implied by loss-function based super learning combined with targeted maximum likelihood learning. Chronologically, his research on statistical learning first focused on the estimating function methodology originally developed by Robins and Rotnitzky. He subsequently developed unified loss-based super learning using unified cross-validation, and targeted maximum likelihood learning.

Mark and James Robins have written a book on a "Unified Approach to Censored Data and Causality," (Springer, 2002) which describes locally optimal estimating function methods to deal with high dimensional complex data sets. These methods model the parameter of interest, and aim to minimize the effect of modeling assumptions on the nuisance parameters, and minimize the need for modeling nuisance parameters. They study double robust estimation procedures, which are guaranteed to always be more nonparametric than a maximum likelihood procedure. Under appropriate assumptions, these estimators are asymptotically normally distributed, and efficient at a user supplied submodel.

Beyond extensive research on the analysis of censored data, Mark and collaborators are heavily involved in research in causal inference. This includes estimation of direct and indirect causal effects in longitudinal studies, estimation of a causal effect of treatment in a randomized trial with non-compliance, and data adaptive estimation of causal effects. In particular, they introduced a new class of history adjusted marginal structural models (generalizing Robins' Marginal Structural Models) which allow adjustment by time-dependent covariates, and estimation of statically optimal dynamic treatment regimes, and models for the estimation of the effect of a user supplied class of realistic individualized treatment rules (simultaneously with Rotnitzky and Robins).

Parameters of interest (such as regressions, densities, hazards) used to answer Public Health or Medical Research questions of interest are typically estimated using an estimator relying on somewhat arbitrary model assumptions (e.g., linear model, covariates used in the model, nuisance parameter model). This is also still true for the estimation function methodology: The estimators for the nuisance parameters in the estimating functions are invariably subject to relative arbitrary choices. Therefore estimator selection procedures need to be developed to assist the statistician with the decision for an appropriate estimator and to reduce the subjective component of estimator selection: estimator selection needs to become data driven within the context of a semiparametric model representing true knowledge.

Estimator selection thus designates a critical component of statistical inferences made. It encompasses in particular a number of selection problems which have traditionally been treated separately in the statistical literature or have not been treated at all: predictor selection based on censored outcomes, predictor selection based on multivariate outcomes, density estimator selection, survival function estimator selection, and counterfactual predictor selection in causal inference, to name a few.

Work by Mark and collaborators (2003) showed that this common issue of estimator selection in Biostatistics can be successfully addressed using a unified cross-validation loss-based estimation methodology. Asymptotic and finite sample results have shown that the proposed cross-validation estimator selection procedure should be conducted more aggressively than believed in the past. These new theoretical results established that data, even finite sample data, contain enough information to engage in an intensive data driven search among candidate estimators using cross-validation to select the estimator used to answer the question of interest in practice.

An important component of Mark's research focuses on statistical methods based on this unified cross-validation loss based estimation methodology in order to provide the end-users with data adaptive statistical routines to conduct parameter estimation in different applications in Genomics, Epidemiology, and Clinical trials. The dominating feature of all applications of such methods is the large number of candidate estimators to consider and thus the need for computationally intensive algorithms to generate these candidate estimators and select the best one.

The proposed estimation methodology consists of combining two components sequentially. The first component is to build a library of candidate estimators of the parameter of interest. This library is built by identifying a collection of candidate estimators and specifying a family of weighted combinations of these candidate estimators identified by a weight-vector. In this manner the library of candidate estimators also consists of specified weighted combinations of candidate estimators. The second component of the methodology is the unified cross-validation methodology to select the best estimator from the library of candidate estimators. This general methodology is extremely flexible and can be adapted to all learning/estimation problems by modifying the definition of the so called loss function which itself defines the parameter of interest.

We showed that, due to the oracle properties of the cross-validation selector we established, the resulting estimator either performs asymptotically as well (w.r.t. the loss-function-based dissimilarity with the true parameter) as the best estimator in the library for the given data set, or, if one of the candidate estimators in the library performs as well as a correctly specified parametric model, then it achieves the optimal parametric rate of convergence. The only conditions of this remarkable general optimality result is that the loss function is uniformly bounded and that the number of candidate estimators (spanning the library of weighted combinations) increases with sample size as a polynomial power. We name this system of learning, for a particular infinite dimensional parameter implied by a loss function, (loss-based) super learning: it represents a system that guarantees that for reasonable sample sizes it outperforms current practice w.r.t. the loss function based dissimilarity with the truth.

One is often interested in one feature of the data generating distribution at a particular time. For example, if prediction is the goal, then one is really concerned with estimation of the infinite dimensional prediction function, but if one wishes to understand the effect of one variable on this prediction function, then that just represents a univariate parameter. Even though the super learner is optimal for the estimation of the infinite dimensional prediction function, it does result in overly biased estimates of smooth features of this infinite dimensional function, such as variable specific effects.

To address optimal estimation of so-called pathwise-differentiable parameters, representing smooth lower dimensional features of the data generating distributions in semiparametric models, we developed so-called targeted maximum likelihood estimation. The target parameter needs to be carefully defined as a mapping from a data generating distribution in the semiparametric model to its value. Targeted maximum likelihood estimation of the target parameter is a two-stage estimation procedure. It takes a first stage estimator such as the super learner of the data generating distribution (or an infinite dimensional parameter of it implied by an appropriate loss function) as input for the second stage that involves a targeted bias reduction step, the so-called targeted maximum likelihood update of the initial estimator. The targeted maximum likelihood step involves defining a least-favorable parametric submodel which represents a family of fluctuations of the initial estimator. The unknown parameter of this parametric least favorable submodel is called a fluctuation parameter. This least favorable parametric submodel is chosen to make estimation of the target parameter hardest among all parametric submodels, thereby making it tailored for bias reduction in the actual semiparametric model. The unknown fluctuation parameter is estimated with standard parametric maximum likelihood estimation, providing an update of the initial estimator. This updating process is iterated till convergence, i.e., till the maximum likelihood estimate of the fluctuation is approximately equal to zero. The resulting modified estimator of the data generating distribution is now mapped into the target parameter resulting in the targeted maximum likelihood estimator of the target parameter.

Targeted maximum likelihood estimation represents an advance to current semiparametric models methodology, including the estimating function methodology, not only resulting in theoretically double robust and efficient estimators and generalizing the classical parametric and semiparametric maximum likelihood estimation, but it also naturally integrates the state of the art loss-based (machine) learning with statistical inference for target parameters. This work was recently published as a book in the Springer Series in Statistics, titled [Targeted Learning: Causal Inference for Observational and Experimental Data](http://www.springer.com/statistics/statistical+theory+and+methods/book/978-1-4419-9781-4). A comprehensive Web site for the text, including R code and supplementary material, has been launched at targetedlearningbook.com.

In order to address the fact that one is typically interested in simultaneously estimating and testing many parameters, Mark and his collaborators have also developed new multiple testing methodology which avoids the need for specifying (e.g., artificial) null distributions for the data generating distributions, and controls (under general distributions) user supplied Type-I error rates such as the Family Wise Error, Generalized Family Wise Error, Tail Probability of the Proportion of False Positives, and False Discovery Rate. This has resulted in a book [Multiple Testing Procedures with Applications to Genomics](http://www.springer.com/life+sci/bioinformatics/book/978-0-387-49316-9) (2008), S. Dudoit and M. J. van der Laan. Springer Series in Statistics.

Mark and collaborators are also carrying out research on targeted adaptive group sequential designs, including targeted maximum likelihood estimation, statistical inference based on martingale central limit theorems, and targeted empirical Bayesian learning.

## Contact

Mark J. van der Laan <br>
University of California at Berkeley <br>
Division of Biostatistics <br>
School of Public Health <br>
Earl Warren Hall #7360 <br>
Berkeley, California 94720-7360 <br>
email: [laan@stat.berkeley.edu](mailto:laan@stat.berkeley.edu) <br>
tel: 510.643.9866 <br>
fax: 510.643.5163 <br>

You may also contact the [Biostatistics Division](https://www.stat.berkeley.edu/~laan/Resources/Resources_subpages/contact.html).